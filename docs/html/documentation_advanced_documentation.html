<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Advanced Documentation &#8212; OnDA 19.09.0.3 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/my-styles.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxcontrib-images/LightBox2/lightbox2/css/lightbox.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script type="text/javascript" src="_static/sphinxcontrib-images/LightBox2/lightbox2/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/sphinxcontrib-images/LightBox2/lightbox2/js/lightbox.min.js"></script>
    <script type="text/javascript" src="_static/sphinxcontrib-images/LightBox2/lightbox2-customize/jquery-noconflict.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The onda Package" href="onda.html" />
    <link rel="prev" title="OnDA Errors and Warnings" href="documentation_errors.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          OnDA</a>
        <span class="navbar-text navbar-version pull-left"><b>19.09.0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="documentation_what_is_an_onda_monitor.html">What is an OnDA Monitor?</a></li>
                <li><a href="documentation_running_onda.html">Running OnDA</a></li>
                <li><a href="#">Advanced Documentation</a></li>
                <li><a href="https://github.com/ondateam/onda">Source Code</a></li>
            
            
              
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="advanced-documentation">
<h1>Advanced Documentation<a class="headerlink" href="#advanced-documentation" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="code-documentation">
<h2>Code Documentation<a class="headerlink" href="#code-documentation" title="Permalink to this headline">¶</a></h2>
<p>Automatically generated documentation from the code of OnDA can be found
<a class="reference internal" href="onda.html"><span class="doc">here</span></a>.</p>
</div>
<div class="section" id="guidelines-for-contributors">
<h2>Guidelines for Contributors<a class="headerlink" href="#guidelines-for-contributors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="version-control">
<h3>Version Control<a class="headerlink" href="#version-control" title="Permalink to this headline">¶</a></h3>
<p>OnDA is developed using the <a class="reference external" href="https://git-scm.com">Git</a> version control system.</p>
<p>OnDA uses the branching strategy proposed by Vincent Driessen and commonly known as
<a class="reference external" href="https://nvie.com/posts/a-successful-git-branching-model">Gitflow</a>.</p>
<p>OnDA follows the <a class="reference external" href="http://www.calver.org">CalVer</a> versioning system. Specifically, it
follows the scheme: <em>YY.MM.MINOR.[MICRO]</em></p>
</div>
<div class="section" id="python">
<h3>Python<a class="headerlink" href="#python" title="Permalink to this headline">¶</a></h3>
<p>OnDA is mainly developed in <a class="reference external" href="https://www.python.org">Python</a>.</p>
<ul class="simple">
<li>All code in OnDA must run with both version 2 and 3 of Python, except for
facility-specific code that specifically requires one of the two versions (for example,
Python 2 for the LCSL facility). The code must specifically support all the currently
active versions of python:<ul>
<li>Python 2<ul>
<li>2.7</li>
</ul>
</li>
<li>Python 3<ul>
<li>3.5</li>
<li>3.6</li>
<li>3.7</li>
</ul>
</li>
</ul>
</li>
<li>The <a class="reference external" href="https://python-future.org">python-future</a> project should be used to ensure that
code contributed to the OnDA project is compatible with all the supported versions of
Python.</li>
<li>The Python coding style should follow for the most part the <a class="reference external" href="https://github.com/google/styleguide/blob/gh-pages/pyguide.md">Google Python
Coding Style</a>.</li>
<li>All docstrings should be written following the <a class="reference external" href="https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html">Google Style</a>.</li>
<li><a class="reference external" href="https://www.pylint.org">Pylint</a> should be run on the code before submission. In
the root folder of the OnDA repository, contributors can find a <em>pylintrc</em> file with
the settings that should be applied when linting OnDA’s code. Please see <a class="reference external" href="http://pylint.pycqa.org/en/latest/user_guide/run.html?highlight=pylintrc">here</a> for
instructions on how to use the pylintrc file.</li>
<li>All submitted code should be formatted using the <a class="reference external" href="https://github.com/psf/black">Black</a> code formatter.</li>
</ul>
</div>
<div class="section" id="c-c">
<h3>C/C++<a class="headerlink" href="#c-c" title="Permalink to this headline">¶</a></h3>
<p>Some extension to OnDA can, for performance reason, be written using the
<a class="reference external" href="https://en.wikipedia.org/wiki/C%2B%2B">C++</a> or <a class="reference external" href="https://en.wikipedia.org/wiki/C_(programming_language)">C</a> programming languages.</p>
<ul class="simple">
<li>All C++ code in OnDA should follow at most the C++98 ISO standard, and the code
should compile on a Linux RHEL7/CentOS7 platform using the development stack that
comes with a standard installation of the system.</li>
<li>Part of the C++11 standard can be used when writing extensions. However, it must be
possible to compile the code using version 4.8 of the <em>gcc</em> compiler (in order to
create the Linux binary Python wheel).</li>
<li>All C code in OnDA should follow at most the C99 ISO standard, and the code should
compile on a Linux RHEL7/CentOS7 platform using the development stack that comes with
a standard installation of the system.</li>
<li>The <a class="reference external" href="http://cython.org">Cython</a> project should be used to interface C/C++ code with
Python.</li>
</ul>
</div>
</div>
<div class="section" id="other-advanced-topics">
<h2>Other Advanced Topics<a class="headerlink" href="#other-advanced-topics" title="Permalink to this headline">¶</a></h2>
<p>This section contains a collection of short essays on several OnDA-related topics.</p>
<div class="section" id="the-onda-monitor-workflow">
<h3>The OnDA Monitor Workflow<a class="headerlink" href="#the-onda-monitor-workflow" title="Permalink to this headline">¶</a></h3>
<p>When an OnDA monitor starts, it first initializes all the worker and master nodes, on a
single or multiple machines, according to the user’s wishes. The first process to
start on the first machine usually takes the role of the master node, while all the
others become workers nodes.</p>
<p>Each node parses the command line arguments, and recovers the source string. It then
reads the configuration file. By default, OnDA looks for a file called <em>monitor.toml</em>
in the current working directory (or a for a different file specified by the user via a
command-line argument).</p>
<p>Every node imports the Python modules for the Parallelization, Processing and Data
Retrieval layers, as specified in the configuration file, then executes the
<em>__init__</em> function from the Processing Layer.</p>
<p>Subsequently, each worker retrieves a <em>data event</em> from the data source. After
retrieving and unpacking the event, it extracts all the data items specified in the
<em>required_data</em> entry of the configuration file. It stores them in a Python dictionary
and calls the <em>process_data</em> function defined in the Processing Layer, passing the
dictionary as an argument.</p>
<p>When the function finishes running, the monitor transmits the Python tuple returned by
the <em>process_data</em> function to the master node. The worker then retrieves the next
event. The master node executes the <em>collect_data</em> function defined in the
Processing Layer every time it receives data from a worker, passing the received data
as an argument to the function.</p>
<p>This process continues indefinitely, or until the data stream ends. In the latter case,
the <em>end_processing</em> function, defined in the Parallelization layer, and optionally
overridden in the Processing Layer is called. All nodes then exit and the monitor
stops.</p>
</div>
<div class="section" id="the-processing-layer">
<h3>The Processing Layer<a class="headerlink" href="#the-processing-layer" title="Permalink to this headline">¶</a></h3>
<p>Writing an OnDA monitoring program consists mainly in writing a Python module, the
Processing Layer, that implements a data analysis pipeline. The Processing Layer module
should contain, apart from some helper functions, just one class: the <em>OndaMonitor</em>
class. The processing logic should be implemented in this class.</p>
<p>The <em>OndaMonitor</em> class must have at least three methods. A developer just needs to
write the implementation for these methods, but it never needs to call any of them.
When the monitoring program runs, the methods are automatically called when
appropriate.</p>
<p>The methods are:</p>
<ol class="arabic">
<li><p class="first"><strong>__init__</strong>: the constructor. This function is executed on both the master and the
worker nodes when the monitor starts. All the monitor initialization code should go
in it. All the class properties needed by the monitor should also be initialized
in this function. Additionally, code that loads external files (for example, a
geometry file, or a file containing a bad pixel mask) should also be placed in this
method: the external data should be read and stored in class properties so that
the other class methods can access it.</p>
<p>This method should usually be divided in three sections. The first should be a
common section with code that should be run on both the master and the worker nodes.
The second and the third, introduced respectively by the code statements
“if role == master” and “if role == worker”, should contain initialization code
specific to one type of node.</p>
</li>
<li><p class="first"><strong>process_data</strong>: this function is executed on each worker node when data is
retrieved from the data source. The function should take only one argument: <em>data</em>.
The retrieved data gets passed to this function via this argument, which is a
dictionary whose keys are the data entries specified in the configuration file under
the <em>required_data</em> entry, and whose values are the data items themselves.</p>
<p>All the logic related to processing a single data event should be implemented in
this method. Ideally, data should be reduced in this function and the raw,
unprocessed information should not be sent to the master node.</p>
<p>The function must return a tuple, where the first entry is a dictionary containing
all the data that should be sent to the master node for aggregation, and the
second entry is the rank of the worker node sending the data.</p>
<p>The developer show not concern himself with how the data is transferred to the
master node: the Parallelization Layer takes care of the transmission.</p>
</li>
<li><p class="first"><strong>collect_data</strong>: this function is executed on the master node every time
data is received from a worker node. This function should implement all the
processing logic that involves more than one event (for example: averaging over many
events, accumulation of events, etc.).</p>
<p>The function should take a single argument: <em>data</em>. The tuple received from the
worker node is passed to the function via the <em>data</em> argument.</p>
<p>The developer can choose what to do with the result of the aggregated data
processing. There is no fixed path. Often the information is broadcasted to a
graphical interface via a network socket, but this is not an obligatory path at all.
The information could also be, for example, printed on the console. If the developer
wants to stream data outside of the OnDA monitor, OnDA provides utilities for this
in the <em>onda.utils.zmq_monitor</em> module.</p>
</li>
</ol>
<p>There is a fourth method that can be implemented by the developer. This is optional:
if the developer does not implement this method in the Processing Layer, OnDA uses the
default implementation from the Processing Layer:</p>
<ol class="arabic" start="4">
<li><p class="first"><strong>end_processing</strong>: this function is executed when the monitoring program finishes
processing the input data, if the input data stream has an end. When the monitor
processes an endless stream of data (for example, most live data streams provided by
the facilities)  this function is never called.</p>
<p>The default implementation of this function, just prints a message to the console
and exits. However, a developer can provide his own implementation, with a different
behavior.</p>
<p>This function is the ideal place for code that cleans up the running environment:
code that closes files, brings down network sockets, etc.</p>
</li>
</ol>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li>Attention should be paid to where the initialization code is placed. The developer
should carefully place the  initialization code in the relevant section (master,
worker or common) of the <em>__init__</em> function. Variables that are initialized, or
operations that are carried out, on node where they are not needed waste resources,
especially memory, and might result in sub-optimal code.</li>
<li>The data being processed should ideally be reduced in the <em>process_data</em> function on
each worker node. Transferring large amount of data between the nodes is not
efficient and should be avoided whenever possible. For example, when crystallography
data is processed and Bragg peaks are extracted from the detector frame data, only
the list of peaks should be sent to the master node, while the frame data should be
dropped. Obviously, this strategy cannot be applied to all cases (a frame viewer,
for example, would need the full frame data), but developers should strive to perform
as much data reduction as possible on the worker nodes.</li>
<li>The <em>OndaMonitor</em> class should be carefully designed and code should be optimized.
For example:<ul>
<li>Only variables that need to be accessed from more than one method should become
class properties. All others can remain simple local variables. Creating class
properties that are not accessed by other methods will clutter the namespace of the
class, and can result in performance degradation.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="algorithms">
<h3>Algorithms<a class="headerlink" href="#algorithms" title="Permalink to this headline">¶</a></h3>
<p>In order to perform data processing, OnDA allows developers to write <em>Algorithms</em>.
Algorithms are essentially Python classes which implement one single data processing
step. Algorithms should be used for operations that must be applied multiple times to
different data items, and need to remember an internal state between applications.
For example, the averaging of detector frame data can be implemented in OnDA as an
algorithm. The algorithm would keep track of the internal intermediate average, and
update it each time it is applied to new frame data.</p>
<p>Algorithms should be used mainly for two types of data processing operations:</p>
<ol class="arabic simple">
<li>Operations where an action defined by the same set of parameters is applied to each
data item retrieved by the monitor. In this case, the internal state is the set of
parameter with which the algorithm is initialized. A good example of this case is a
peak finding algorithm, which is initialized with a set of parameters and then
applied to each frame data retrieved by the monitor. Another good example is a dark
calibration correction algorithm, where the same dark calibration data (with which
the algorithm is initialized) is applied to each retrieved detector data frame.</li>
<li>Operations where an action applied to each retrieved data item updates the internal
state. An good example of this case is an algorithm that computes a running average:
every time the algorithm is applied to retrieved data, the internal current average
is updated.</li>
</ol>
<p>OnDA provides some pre-packaged algorithms for common data processing operations (peak
finding, data accumulation, etc.) in the <em>onda.algorithms</em> Python sub-package.</p>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li>For data processing actions that don’t fall in the two cases described above,
and do not need to keep track of an internal state, functions can often be used in
place of algorithms. For example, the computation of an autocorrelation, the sum of
the intensity observed in a detector frame, are operations that do not store to store
any persisent information when applied multiple times. They can be implemented as
simple functions instead of algorithms.</li>
</ul>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 
    2014-2019 Deutsches Elektronen-Synchrotron DESY, a research centre of
    the Helmholtz Association
.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.5.<br/>
    </p>
  </div>
</footer>
  </body>
</html>